{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gpytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27ZiJrYlNO0Z",
        "outputId": "308ae385-36f1-4bfb-fa1b-e91d661c0440"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpytorch\n",
            "  Downloading gpytorch-1.14-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting jaxtyping (from gpytorch)\n",
            "  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.12/dist-packages (from gpytorch) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from gpytorch) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from gpytorch) (1.16.1)\n",
            "Collecting linear-operator>=0.6 (from gpytorch)\n",
            "  Downloading linear_operator-0.6-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from linear-operator>=0.6->gpytorch) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy>=1.6.0->gpytorch) (2.0.2)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping->gpytorch)\n",
            "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->gpytorch) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->gpytorch) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->linear-operator>=0.6->gpytorch) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->linear-operator>=0.6->gpytorch) (3.0.2)\n",
            "Downloading gpytorch-1.14-py3-none-any.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.7/277.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading linear_operator-0.6-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.3/176.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: wadler-lindig, jaxtyping, linear-operator, gpytorch\n",
            "Successfully installed gpytorch-1.14 jaxtyping-0.3.2 linear-operator-0.6 wadler-lindig-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h0_53F4iLJGf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import gpytorch\n",
        "from gpytorch.models import ApproximateGP\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv('/content/kathmandu_historical_air_quality_20250825_062407.csv')\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])"
      ],
      "metadata": {
        "id": "Edo0BWwmLekW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)"
      ],
      "metadata": {
        "id": "LVjOlDALLiIU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "le_station = LabelEncoder()\n",
        "df['station_encoded'] = le_station.fit_transform(df['station_id'])\n",
        "le_season = LabelEncoder()\n",
        "df['season_encoded'] = le_season.fit_transform(df['season'])\n"
      ],
      "metadata": {
        "id": "CTBUOMG_LimR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = [\n",
        "    'temperature', 'humidity', 'pressure', 'wind_speed', 'wind_direction',\n",
        "    'precipitation', 'lat', 'lng', 'elevation', 'aod_550nm',\n",
        "    'hour_sin', 'hour_cos', 'month_sin', 'month_cos',\n",
        "    'weekday', 'is_weekend', 'high_pollution_season', 'festival_season',\n",
        "    'station_encoded', 'season_encoded'\n",
        "]\n"
      ],
      "metadata": {
        "id": "PW76CS0ULlPS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[features].values\n",
        "y = df['pm2_5'].values\n",
        "X = np.nan_to_num(X, nan=np.nanmean(X, axis=0))\n",
        "\n",
        "sort_idx = df['datetime'].argsort()\n",
        "X_sorted, y_sorted = X[sort_idx], y[sort_idx]\n",
        "df_sorted = df.iloc[sort_idx].reset_index(drop=True)\n",
        "\n",
        "n_total = len(X_sorted)\n",
        "n_train = int(0.70 * n_total)\n",
        "n_val = int(0.15 * n_total)\n",
        "\n",
        "X_train = X_sorted[:n_train]\n",
        "y_train = y_sorted[:n_train]\n",
        "X_val = X_sorted[n_train:n_train+n_val]\n",
        "y_val = y_sorted[n_train:n_train+n_val]\n",
        "X_test = X_sorted[n_train+n_val:]\n",
        "y_test = y_sorted[n_train+n_val:]\n",
        "\n",
        "scaler_X, scaler_y = StandardScaler(), StandardScaler()\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
        "X_val_scaled = scaler_X.transform(X_val)\n",
        "y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1)).ravel()\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "df_test = df_sorted.iloc[n_train+n_val:].copy()"
      ],
      "metadata": {
        "id": "Tw2Oq2mlLnrg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SparseGPModel(ApproximateGP):\n",
        "    def __init__(self, inducing_points, num_dims):\n",
        "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
        "            inducing_points.size(0)\n",
        "        )\n",
        "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
        "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
        "        )\n",
        "        super().__init__(variational_strategy)\n",
        "        self.mean_module = gpytorch.means.ConstantMean()\n",
        "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
        "            gpytorch.kernels.RBFKernel(ard_num_dims=num_dims)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "def train_sparse_gp(X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled,\n",
        "                   n_inducing=1200, num_epochs=120):\n",
        "    kmeans = KMeans(n_clusters=n_inducing, random_state=42, n_init=10)\n",
        "    inducing_points = torch.tensor(\n",
        "        kmeans.fit(X_train_scaled).cluster_centers_, dtype=torch.float32\n",
        "    ).to(device)\n",
        "\n",
        "    model = SparseGPModel(inducing_points, X_train_scaled.shape[1]).to(device)\n",
        "    likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
        "\n",
        "    model.train()\n",
        "    likelihood.train()\n",
        "\n",
        "    optimizer = torch.optim.Adam([\n",
        "        {'params': model.parameters(), 'lr': 0.01},\n",
        "        {'params': likelihood.parameters(), 'lr': 0.01},\n",
        "    ], weight_decay=1e-4)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', patience=10, factor=0.7, min_lr=1e-5\n",
        "    )\n",
        "\n",
        "    mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=len(y_train_scaled))\n",
        "\n",
        "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
        "    y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).to(device)\n",
        "    X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32).to(device)\n",
        "    y_val_tensor = torch.tensor(y_val_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    batch_size = 1024\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        likelihood.train()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for i in range(0, len(X_train_tensor), batch_size):\n",
        "            batch_x = X_train_tensor[i:i+batch_size]\n",
        "            batch_y = y_train_tensor[i:i+batch_size]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(batch_x)\n",
        "            loss = -mll(output, batch_y)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        likelihood.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val_tensor)\n",
        "            val_loss = -mll(val_output, y_val_tensor).item()\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            best_model_state = {\n",
        "                'model': model.state_dict(),\n",
        "                'likelihood': likelihood.state_dict(),\n",
        "            }\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= 15:\n",
        "            break\n",
        "\n",
        "    if 'best_model_state' in locals():\n",
        "        model.load_state_dict(best_model_state['model'])\n",
        "        likelihood.load_state_dict(best_model_state['likelihood'])\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    return model, likelihood, training_time\n",
        "\n",
        "gp_model, gp_likelihood, gp_training_time = train_sparse_gp(\n",
        "    X_train_scaled, y_train_scaled, X_val_scaled, y_val_scaled\n",
        ")"
      ],
      "metadata": {
        "id": "GqheC30cLrjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_models = {}\n",
        "baseline_times = {}\n",
        "\n",
        "start_time = time.time()\n",
        "rf_model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1,\n",
        "                                max_depth=20, min_samples_split=5)\n",
        "rf_model.fit(X_train_scaled, y_train_scaled)\n",
        "baseline_models['Random Forest'] = rf_model\n",
        "baseline_times['Random Forest'] = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "gb_model = GradientBoostingRegressor(n_estimators=200, random_state=42,\n",
        "                                   learning_rate=0.1, max_depth=6)\n",
        "gb_model.fit(X_train_scaled, y_train_scaled)\n",
        "baseline_models['Gradient Boosting'] = gb_model\n",
        "baseline_times['Gradient Boosting'] = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "svr_model = SVR(kernel='rbf', C=10, gamma='scale', epsilon=0.1)\n",
        "svr_model.fit(X_train_scaled, y_train_scaled)\n",
        "baseline_models['SVR'] = svr_model\n",
        "baseline_times['SVR'] = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_scaled, y_train_scaled)\n",
        "baseline_models['Linear Regression'] = lr_model\n",
        "baseline_times['Linear Regression'] = time.time() - start_time"
      ],
      "metadata": {
        "id": "Wg3CHI58LyXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-8))) * 100\n",
        "    return {'RMSE': rmse, 'MAE': mae, 'R²': r2, 'MAPE': mape}\n",
        "\n",
        "gp_model.eval()\n",
        "gp_likelihood.eval()\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    gp_pred_dist = gp_likelihood(gp_model(X_test_tensor))\n",
        "    gp_pred_scaled = gp_pred_dist.mean.cpu().numpy()\n",
        "    gp_var_scaled = gp_pred_dist.variance.cpu().numpy()\n",
        "\n",
        "gp_pred = scaler_y.inverse_transform(gp_pred_scaled.reshape(-1, 1)).ravel()\n",
        "gp_std = np.sqrt(gp_var_scaled) * scaler_y.scale_\n",
        "y_test_orig = scaler_y.inverse_transform(scaler_y.transform(y_test.reshape(-1, 1))).ravel()\n",
        "\n",
        "baseline_preds = {}\n",
        "for name, model in baseline_models.items():\n",
        "    pred_scaled = model.predict(X_test_scaled)\n",
        "    pred_orig = scaler_y.inverse_transform(pred_scaled.reshape(-1, 1)).ravel()\n",
        "    baseline_preds[name] = pred_orig\n",
        "\n",
        "gp_metrics = calculate_metrics(y_test_orig, gp_pred)\n",
        "residuals = np.abs(y_test_orig - gp_pred)\n",
        "within_1std = (residuals <= gp_std).mean() * 100\n",
        "gp_metrics['Uncertainty Calib'] = within_1std\n",
        "\n",
        "baseline_metrics = {}\n",
        "for name, pred in baseline_preds.items():\n",
        "    baseline_metrics[name] = calculate_metrics(y_test_orig, pred)"
      ],
      "metadata": {
        "id": "suySDu9-L10S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_baseline = min(baseline_metrics.keys(), key=lambda x: baseline_metrics[x]['RMSE'])\n",
        "best_baseline_rmse = baseline_metrics[best_baseline]['RMSE']\n",
        "gp_improvement = ((best_baseline_rmse - gp_metrics['RMSE']) / best_baseline_rmse) * 100\n",
        "\n",
        "df_test['gp_predictions'] = gp_pred\n",
        "seasonal_performance = {}\n",
        "for season in df_test['season'].unique():\n",
        "    season_mask = df_test['season'] == season\n",
        "    if season_mask.sum() > 0:\n",
        "        season_data = df_test[season_mask]\n",
        "        season_rmse = np.sqrt(mean_squared_error(season_data['pm2_5'], season_data['gp_predictions']))\n",
        "        season_r2 = r2_score(season_data['pm2_5'], season_data['gp_predictions'])\n",
        "        seasonal_performance[season] = {\n",
        "            'RMSE': season_rmse,\n",
        "            'R²': season_r2,\n",
        "            'Count': season_mask.sum(),\n",
        "            'Mean_PM25': season_data['pm2_5'].mean()\n",
        "        }\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "models = ['Sparse GP'] + list(baseline_metrics.keys())\n",
        "rmse_values = [gp_metrics['RMSE']] + [baseline_metrics[m]['RMSE'] for m in baseline_metrics.keys()]\n",
        "colors = ['red'] + ['lightblue'] * (len(models) - 1)\n",
        "bars = axes[0,0].bar(models, rmse_values, color=colors, alpha=0.7)\n",
        "axes[0,0].set_title('RMSE Comparison Across All Models')\n",
        "axes[0,0].set_ylabel('RMSE (μg/m³)')\n",
        "axes[0,0].tick_params(axis='x', rotation=45)\n",
        "for bar, val in zip(bars, rmse_values):\n",
        "    axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3,\n",
        "                   f'{val:.1f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "scatter = axes[0,1].scatter(y_test_orig, gp_pred, alpha=0.6, s=15, c=gp_std, cmap='viridis')\n",
        "min_val = min(y_test_orig.min(), gp_pred.min())\n",
        "max_val = max(y_test_orig.max(), gp_pred.max())\n",
        "axes[0,1].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
        "axes[0,1].set_xlabel('Actual PM2.5 (μg/m³)')\n",
        "axes[0,1].set_ylabel('Predicted PM2.5 (μg/m³)')\n",
        "axes[0,1].set_title(f'GP Predictions (R² = {gp_metrics[\"R²\"]:.3f})')\n",
        "plt.colorbar(scatter, ax=axes[0,1], label='Uncertainty (μg/m³)')\n",
        "\n",
        "r2_values = [gp_metrics['R²']] + [baseline_metrics[m]['R²'] for m in baseline_metrics.keys()]\n",
        "axes[0,2].bar(models, r2_values, color=colors, alpha=0.7)\n",
        "axes[0,2].set_title('R² Comparison Across All Models')\n",
        "axes[0,2].set_ylabel('R² Score')\n",
        "axes[0,2].tick_params(axis='x', rotation=45)\n",
        "for i, val in enumerate(r2_values):\n",
        "    axes[0,2].text(i, val + 0.01, f'{val:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "n_show = min(300, len(y_test_orig))\n",
        "x_time = range(n_show)\n",
        "axes[1,0].plot(x_time, y_test_orig[:n_show], 'b-', label='Actual', alpha=0.8, linewidth=1)\n",
        "axes[1,0].plot(x_time, gp_pred[:n_show], 'r-', label='GP Predicted', linewidth=1)\n",
        "axes[1,0].fill_between(x_time,\n",
        "                      (gp_pred - 1.96*gp_std)[:n_show],\n",
        "                      (gp_pred + 1.96*gp_std)[:n_show],\n",
        "                      alpha=0.3, color='red', label='95% CI')\n",
        "axes[1,0].set_xlabel('Time Index')\n",
        "axes[1,0].set_ylabel('PM2.5 (μg/m³)')\n",
        "axes[1,0].set_title('Time Series with Uncertainty Bands')\n",
        "axes[1,0].legend()\n",
        "\n",
        "seasons = list(seasonal_performance.keys())\n",
        "season_rmse = [seasonal_performance[s]['RMSE'] for s in seasons]\n",
        "season_colors = ['brown', 'green', 'orange', 'blue'][:len(seasons)]\n",
        "axes[1,1].bar(seasons, season_rmse, color=season_colors, alpha=0.7)\n",
        "axes[1,1].set_title('GP Performance by Season')\n",
        "axes[1,1].set_ylabel('RMSE (μg/m³)')\n",
        "axes[1,1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "feature_importance = rf_model.feature_importances_\n",
        "top_indices = np.argsort(feature_importance)[-10:]\n",
        "axes[1,2].barh(range(len(top_indices)), feature_importance[top_indices])\n",
        "axes[1,2].set_yticks(range(len(top_indices)))\n",
        "axes[1,2].set_yticklabels([features[i] for i in top_indices])\n",
        "axes[1,2].set_xlabel('Feature Importance (RF)')\n",
        "axes[1,2].set_title('Top 10 Most Important Features')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lQMv5UwnL5VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data for plotting\n",
        "models = ['Sparse GP'] + list(baseline_metrics.keys())\n",
        "rmse_values = [gp_metrics['RMSE']] + [baseline_metrics[m]['RMSE'] for m in baseline_metrics.keys()]\n",
        "colors = ['red'] + ['lightblue'] * (len(models) - 1)\n",
        "\n",
        "# Create plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(models, rmse_values, color=colors, alpha=0.7)\n",
        "plt.title('RMSE Comparison Across All Models')\n",
        "plt.ylabel('RMSE (μg/m³)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "for bar, val in zip(bars, rmse_values):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3,\n",
        "             f'{val:.1f}', ha='center', va='bottom', fontsize=9)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0g_jVkRRMHpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GP prediction uncertanity\n",
        "import numpy as np\n",
        "\n",
        "# Data for plotting\n",
        "min_val = min(y_test_orig.min(), gp_pred.min())\n",
        "max_val = max(y_test_orig.max(), gp_pred.max())\n",
        "\n",
        "# Create plot\n",
        "plt.figure(figsize=(8, 8))\n",
        "scatter = plt.scatter(y_test_orig, gp_pred, alpha=0.6, s=15, c=gp_std, cmap='viridis')\n",
        "plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
        "plt.xlabel('Actual PM2.5 (μg/m³)')\n",
        "plt.ylabel('Predicted PM2.5 (μg/m³)')\n",
        "plt.title(f'GP Predictions (R² = {gp_metrics[\"R²\"]:.3f})')\n",
        "plt.colorbar(scatter, label='Uncertainty (μg/m³)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T8sfzoSPMIoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model comparison\n",
        "# Data for plotting\n",
        "models = ['Sparse GP'] + list(baseline_metrics.keys())\n",
        "r2_values = [gp_metrics['R²']] + [baseline_metrics[m]['R²'] for m in baseline_metrics.keys()]\n",
        "colors = ['red'] + ['lightblue'] * (len(models) - 1)\n",
        "\n",
        "# Create plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(models, r2_values, color=colors, alpha=0.7)\n",
        "plt.title('R² Comparison Across All Models')\n",
        "plt.ylabel('R² Score')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "for i, val in enumerate(r2_values):\n",
        "    plt.text(i, val + 0.01, f'{val:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VN2X59WmMKvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# time series with uncertainity plot\n",
        "\n",
        "# Data for plotting\n",
        "n_show = min(300, len(y_test_orig))\n",
        "x_time = range(n_show)\n",
        "\n",
        "# Create plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x_time, y_test_orig[:n_show], 'b-', label='Actual', alpha=0.8, linewidth=1)\n",
        "plt.plot(x_time, gp_pred[:n_show], 'r-', label='GP Predicted', linewidth=1)\n",
        "plt.fill_between(x_time,\n",
        "                 (gp_pred - 1.96*gp_std)[:n_show],\n",
        "                 (gp_pred + 1.96*gp_std)[:n_show],\n",
        "                 alpha=0.3, color='red', label='95% CI')\n",
        "plt.xlabel('Time Index')\n",
        "plt.ylabel('PM2.5 (μg/m³)')\n",
        "plt.title('Time Series with Uncertainty Bands')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MNIrGqogMQ0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sesonal variation\n",
        "# Data for plotting\n",
        "seasons = list(seasonal_performance.keys())\n",
        "season_rmse = [seasonal_performance[s]['RMSE'] for s in seasons]\n",
        "season_colors = ['brown', 'green', 'orange', 'blue'][:len(seasons)]\n",
        "\n",
        "# Create plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(seasons, season_rmse, color=season_colors, alpha=0.7)\n",
        "plt.title('GP Performance by Season')\n",
        "plt.ylabel('RMSE (μg/m³)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "214DZuJmMRwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature importance plot\n",
        "# Data for plotting\n",
        "feature_importance = rf_model.feature_importances_\n",
        "top_indices = np.argsort(feature_importance)[-10:]\n",
        "\n",
        "# Create plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(range(len(top_indices)), feature_importance[top_indices])\n",
        "plt.yticks(range(len(top_indices)), [features[i] for i in top_indices])\n",
        "plt.xlabel('Feature Importance (RF)')\n",
        "plt.title('Top 10 Most Important Features')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YGOxiucdMXUW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}